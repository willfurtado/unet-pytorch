{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a402365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb2430",
   "metadata": {},
   "source": [
    "# Dataset Exploration\n",
    "\n",
    "Run the following cells to get an overview of the flood image dataset and visualize training examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6059dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = \"../data\"\n",
    "\n",
    "frame_path = os.path.join(root_data_path, \"image\")\n",
    "mask_path = os.path.join(root_data_path, \"mask\")\n",
    "\n",
    "# Get list of all available frames and masks\n",
    "available_frames = sorted([os.path.join(frame_path, path) for path in os.listdir(frame_path)])\n",
    "available_masks = sorted([os.path.join(mask_path, path) for path in os.listdir(mask_path)])\n",
    "\n",
    "print(f\"Num Frames: {len(available_frames):,}\")\n",
    "print(f\"Num Masks: {len(available_masks):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55722d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "frame = Image.open(available_frames[idx]).convert(\"RGB\")\n",
    "mask = Image.open(available_masks[idx]).convert(\"L\")\n",
    "\n",
    "display(frame)\n",
    "display(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6b01d",
   "metadata": {},
   "source": [
    "## Train & Validation Split\n",
    "\n",
    "In order to evaluate our model as it trains, we can split our dataset into training and validation segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccb10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = os.path.join(root_data_path, \"metadata.csv\")\n",
    "meta_df = pd.read_csv(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle rows of DataFrame with random state\n",
    "shuffled_df = meta_df.sample(frac=1.0, random_state=42)\n",
    "\n",
    "# Take top X% of rows, where X is the percentage of training data to use\n",
    "# For this example, we use 85%\n",
    "training_proportion = 0.85\n",
    "num_training_examples = int(training_proportion * meta_df.shape[0])\n",
    "\n",
    "train_df = shuffled_df.iloc[:num_training_examples, :]\n",
    "val_df = shuffled_df.iloc[num_training_examples:, :]\n",
    "\n",
    "print(f\"Num Training Examples: {train_df.shape[0]}\")\n",
    "print(f\"Num Validation Examples: {val_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(root_data_path, \"train.csv\")\n",
    "val_path = os.path.join(root_data_path, \"val.csv\")\n",
    "\n",
    "# Write new CSV files for train and val\n",
    "write_new_files = False\n",
    "\n",
    "if write_new_files:\n",
    "    train_df.to_csv(train_path, index=None)\n",
    "    val_df.to_csv(val_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182b010-82c3-477f-b19d-114afc31c190",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "Create the training and validation datasets with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e55e53-cdbe-4f16-95dc-39ae8ce6f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet.dataset import TrainFloodDataset, ValFloodDataset\n",
    "from unet.utils import visualize_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfe29e-6880-490b-a285-9c23fe3b2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainFloodDataset(\n",
    "    examples_path=\"../data/train.csv\", \n",
    "    image_dir=\"../data/image\", \n",
    "    mask_dir=\"../data/mask\",\n",
    "    resize_height=360,\n",
    "    apply_augmentations=True,\n",
    ")\n",
    "\n",
    "val_dataset = ValFloodDataset(\n",
    "    examples_path=\"../data/val.csv\", \n",
    "    image_dir=\"../data/image\", \n",
    "    mask_dir=\"../data/mask\",\n",
    "    resize_height=360,\n",
    "    apply_augmentations=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040efb56-1560-40fb-a0ca-4ea5b073bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = visualize_example(dataset=train_dataset, idx=3, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3341d0-405f-49de-bae0-ec82ed090071",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = visualize_example(dataset=val_dataset, idx=12, alpha=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
